# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: nlp.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='nlp.proto',
  package='nlp',
  syntax='proto3',
  serialized_pb=_b('\n\tnlp.proto\x12\x03nlp\"#\n\x0fSentenceRequest\x12\x10\n\x08sentence\x18\x01 \x01(\t\"8\n\x10SentenceRequest2\x12\x11\n\tsentence1\x18\x01 \x01(\t\x12\x11\n\tsentence2\x18\x02 \x01(\t\" \n\rSentenceReply\x12\x0f\n\x07message\x18\x01 \x01(\t2\x99\x04\n\x03Nlp\x12\x39\n\x0bWordSegment\x12\x14.nlp.SentenceRequest\x1a\x12.nlp.SentenceReply\"\x00\x12\x34\n\x06PosTag\x12\x14.nlp.SentenceRequest\x1a\x12.nlp.SentenceReply\"\x00\x12\x44\n\x16NamedIdentityRecognize\x12\x14.nlp.SentenceRequest\x1a\x12.nlp.SentenceReply\"\x00\x12\x38\n\nOrgMatcher\x12\x14.nlp.SentenceRequest\x1a\x12.nlp.SentenceReply\"\x00\x12\x38\n\nDependency\x12\x14.nlp.SentenceRequest\x1a\x12.nlp.SentenceReply\"\x00\x12\x38\n\nEntityLink\x12\x14.nlp.SentenceRequest\x1a\x12.nlp.SentenceReply\"\x00\x12<\n\x0e\x43ompanySegment\x12\x14.nlp.SentenceRequest\x1a\x12.nlp.SentenceReply\"\x00\x12\x32\n\x03\x42id\x12\x15.nlp.SentenceRequest2\x1a\x12.nlp.SentenceReply\"\x00\x12;\n\x0c\x45ventExtract\x12\x15.nlp.SentenceRequest2\x1a\x12.nlp.SentenceReply\"\x00\x42)\n\x15\x63om.haizhi.nlp.serverB\tHaiZhiNlpP\x01\xa2\x02\x02HZb\x06proto3')
)
_sym_db.RegisterFileDescriptor(DESCRIPTOR)




_SENTENCEREQUEST = _descriptor.Descriptor(
  name='SentenceRequest',
  full_name='nlp.SentenceRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='sentence', full_name='nlp.SentenceRequest.sentence', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=18,
  serialized_end=53,
)


_SENTENCEREQUEST2 = _descriptor.Descriptor(
  name='SentenceRequest2',
  full_name='nlp.SentenceRequest2',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='sentence1', full_name='nlp.SentenceRequest2.sentence1', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='sentence2', full_name='nlp.SentenceRequest2.sentence2', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=55,
  serialized_end=111,
)


_SENTENCEREPLY = _descriptor.Descriptor(
  name='SentenceReply',
  full_name='nlp.SentenceReply',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='message', full_name='nlp.SentenceReply.message', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=113,
  serialized_end=145,
)

DESCRIPTOR.message_types_by_name['SentenceRequest'] = _SENTENCEREQUEST
DESCRIPTOR.message_types_by_name['SentenceRequest2'] = _SENTENCEREQUEST2
DESCRIPTOR.message_types_by_name['SentenceReply'] = _SENTENCEREPLY

SentenceRequest = _reflection.GeneratedProtocolMessageType('SentenceRequest', (_message.Message,), dict(
  DESCRIPTOR = _SENTENCEREQUEST,
  __module__ = 'nlp_pb2'
  # @@protoc_insertion_point(class_scope:nlp.SentenceRequest)
  ))
_sym_db.RegisterMessage(SentenceRequest)

SentenceRequest2 = _reflection.GeneratedProtocolMessageType('SentenceRequest2', (_message.Message,), dict(
  DESCRIPTOR = _SENTENCEREQUEST2,
  __module__ = 'nlp_pb2'
  # @@protoc_insertion_point(class_scope:nlp.SentenceRequest2)
  ))
_sym_db.RegisterMessage(SentenceRequest2)

SentenceReply = _reflection.GeneratedProtocolMessageType('SentenceReply', (_message.Message,), dict(
  DESCRIPTOR = _SENTENCEREPLY,
  __module__ = 'nlp_pb2'
  # @@protoc_insertion_point(class_scope:nlp.SentenceReply)
  ))
_sym_db.RegisterMessage(SentenceReply)


DESCRIPTOR.has_options = True
DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\n\025com.haizhi.nlp.serverB\tHaiZhiNlpP\001\242\002\002HZ'))
try:
  # THESE ELEMENTS WILL BE DEPRECATED.
  # Please use the generated *_pb2_grpc.py files instead.
  import grpc
  from grpc.framework.common import cardinality
  from grpc.framework.interfaces.face import utilities as face_utilities
  from grpc.beta import implementations as beta_implementations
  from grpc.beta import interfaces as beta_interfaces


  class NlpStub(object):
    """The nlp service definition.
    """

    def __init__(self, channel):
      """Constructor.

      Args:
        channel: A grpc.Channel.
      """
      self.WordSegment = channel.unary_unary(
          '/nlp.Nlp/WordSegment',
          request_serializer=SentenceRequest.SerializeToString,
          response_deserializer=SentenceReply.FromString,
          )
      self.PosTag = channel.unary_unary(
          '/nlp.Nlp/PosTag',
          request_serializer=SentenceRequest.SerializeToString,
          response_deserializer=SentenceReply.FromString,
          )
      self.NamedIdentityRecognize = channel.unary_unary(
          '/nlp.Nlp/NamedIdentityRecognize',
          request_serializer=SentenceRequest.SerializeToString,
          response_deserializer=SentenceReply.FromString,
          )
      self.OrgMatcher = channel.unary_unary(
          '/nlp.Nlp/OrgMatcher',
          request_serializer=SentenceRequest.SerializeToString,
          response_deserializer=SentenceReply.FromString,
          )
      self.Dependency = channel.unary_unary(
          '/nlp.Nlp/Dependency',
          request_serializer=SentenceRequest.SerializeToString,
          response_deserializer=SentenceReply.FromString,
          )
      self.EntityLink = channel.unary_unary(
          '/nlp.Nlp/EntityLink',
          request_serializer=SentenceRequest.SerializeToString,
          response_deserializer=SentenceReply.FromString,
          )
      self.CompanySegment = channel.unary_unary(
          '/nlp.Nlp/CompanySegment',
          request_serializer=SentenceRequest.SerializeToString,
          response_deserializer=SentenceReply.FromString,
          )
      self.Bid = channel.unary_unary(
          '/nlp.Nlp/Bid',
          request_serializer=SentenceRequest2.SerializeToString,
          response_deserializer=SentenceReply.FromString,
          )
      self.EventExtract = channel.unary_unary(
          '/nlp.Nlp/EventExtract',
          request_serializer=SentenceRequest2.SerializeToString,
          response_deserializer=SentenceReply.FromString,
          )


  class NlpServicer(object):
    """The nlp service definition.
    """

    def WordSegment(self, request, context):
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def PosTag(self, request, context):
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def NamedIdentityRecognize(self, request, context):
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def OrgMatcher(self, request, context):
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def Dependency(self, request, context):
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def EntityLink(self, request, context):
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def CompanySegment(self, request, context):
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def Bid(self, request, context):
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def EventExtract(self, request, context):
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')


  def add_NlpServicer_to_server(servicer, server):
    rpc_method_handlers = {
        'WordSegment': grpc.unary_unary_rpc_method_handler(
            servicer.WordSegment,
            request_deserializer=SentenceRequest.FromString,
            response_serializer=SentenceReply.SerializeToString,
        ),
        'PosTag': grpc.unary_unary_rpc_method_handler(
            servicer.PosTag,
            request_deserializer=SentenceRequest.FromString,
            response_serializer=SentenceReply.SerializeToString,
        ),
        'NamedIdentityRecognize': grpc.unary_unary_rpc_method_handler(
            servicer.NamedIdentityRecognize,
            request_deserializer=SentenceRequest.FromString,
            response_serializer=SentenceReply.SerializeToString,
        ),
        'OrgMatcher': grpc.unary_unary_rpc_method_handler(
            servicer.OrgMatcher,
            request_deserializer=SentenceRequest.FromString,
            response_serializer=SentenceReply.SerializeToString,
        ),
        'Dependency': grpc.unary_unary_rpc_method_handler(
            servicer.Dependency,
            request_deserializer=SentenceRequest.FromString,
            response_serializer=SentenceReply.SerializeToString,
        ),
        'EntityLink': grpc.unary_unary_rpc_method_handler(
            servicer.EntityLink,
            request_deserializer=SentenceRequest.FromString,
            response_serializer=SentenceReply.SerializeToString,
        ),
        'CompanySegment': grpc.unary_unary_rpc_method_handler(
            servicer.CompanySegment,
            request_deserializer=SentenceRequest.FromString,
            response_serializer=SentenceReply.SerializeToString,
        ),
        'Bid': grpc.unary_unary_rpc_method_handler(
            servicer.Bid,
            request_deserializer=SentenceRequest2.FromString,
            response_serializer=SentenceReply.SerializeToString,
        ),
        'EventExtract': grpc.unary_unary_rpc_method_handler(
            servicer.EventExtract,
            request_deserializer=SentenceRequest2.FromString,
            response_serializer=SentenceReply.SerializeToString,
        ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
        'nlp.Nlp', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


  class BetaNlpServicer(object):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0."""
    """The nlp service definition.
    """
    def WordSegment(self, request, context):
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def PosTag(self, request, context):
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def NamedIdentityRecognize(self, request, context):
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def OrgMatcher(self, request, context):
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def Dependency(self, request, context):
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def EntityLink(self, request, context):
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def CompanySegment(self, request, context):
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def Bid(self, request, context):
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def EventExtract(self, request, context):
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)


  class BetaNlpStub(object):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0."""
    """The nlp service definition.
    """
    def WordSegment(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      raise NotImplementedError()
    WordSegment.future = None
    def PosTag(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      raise NotImplementedError()
    PosTag.future = None
    def NamedIdentityRecognize(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      raise NotImplementedError()
    NamedIdentityRecognize.future = None
    def OrgMatcher(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      raise NotImplementedError()
    OrgMatcher.future = None
    def Dependency(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      raise NotImplementedError()
    Dependency.future = None
    def EntityLink(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      raise NotImplementedError()
    EntityLink.future = None
    def CompanySegment(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      raise NotImplementedError()
    CompanySegment.future = None
    def Bid(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      raise NotImplementedError()
    Bid.future = None
    def EventExtract(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      raise NotImplementedError()
    EventExtract.future = None


  def beta_create_Nlp_server(servicer, pool=None, pool_size=None, default_timeout=None, maximum_timeout=None):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This function was
    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0"""
    request_deserializers = {
      ('nlp.Nlp', 'Bid'): SentenceRequest2.FromString,
      ('nlp.Nlp', 'CompanySegment'): SentenceRequest.FromString,
      ('nlp.Nlp', 'Dependency'): SentenceRequest.FromString,
      ('nlp.Nlp', 'EntityLink'): SentenceRequest.FromString,
      ('nlp.Nlp', 'EventExtract'): SentenceRequest2.FromString,
      ('nlp.Nlp', 'NamedIdentityRecognize'): SentenceRequest.FromString,
      ('nlp.Nlp', 'OrgMatcher'): SentenceRequest.FromString,
      ('nlp.Nlp', 'PosTag'): SentenceRequest.FromString,
      ('nlp.Nlp', 'WordSegment'): SentenceRequest.FromString,
    }
    response_serializers = {
      ('nlp.Nlp', 'Bid'): SentenceReply.SerializeToString,
      ('nlp.Nlp', 'CompanySegment'): SentenceReply.SerializeToString,
      ('nlp.Nlp', 'Dependency'): SentenceReply.SerializeToString,
      ('nlp.Nlp', 'EntityLink'): SentenceReply.SerializeToString,
      ('nlp.Nlp', 'EventExtract'): SentenceReply.SerializeToString,
      ('nlp.Nlp', 'NamedIdentityRecognize'): SentenceReply.SerializeToString,
      ('nlp.Nlp', 'OrgMatcher'): SentenceReply.SerializeToString,
      ('nlp.Nlp', 'PosTag'): SentenceReply.SerializeToString,
      ('nlp.Nlp', 'WordSegment'): SentenceReply.SerializeToString,
    }
    method_implementations = {
      ('nlp.Nlp', 'Bid'): face_utilities.unary_unary_inline(servicer.Bid),
      ('nlp.Nlp', 'CompanySegment'): face_utilities.unary_unary_inline(servicer.CompanySegment),
      ('nlp.Nlp', 'Dependency'): face_utilities.unary_unary_inline(servicer.Dependency),
      ('nlp.Nlp', 'EntityLink'): face_utilities.unary_unary_inline(servicer.EntityLink),
      ('nlp.Nlp', 'EventExtract'): face_utilities.unary_unary_inline(servicer.EventExtract),
      ('nlp.Nlp', 'NamedIdentityRecognize'): face_utilities.unary_unary_inline(servicer.NamedIdentityRecognize),
      ('nlp.Nlp', 'OrgMatcher'): face_utilities.unary_unary_inline(servicer.OrgMatcher),
      ('nlp.Nlp', 'PosTag'): face_utilities.unary_unary_inline(servicer.PosTag),
      ('nlp.Nlp', 'WordSegment'): face_utilities.unary_unary_inline(servicer.WordSegment),
    }
    server_options = beta_implementations.server_options(request_deserializers=request_deserializers, response_serializers=response_serializers, thread_pool=pool, thread_pool_size=pool_size, default_timeout=default_timeout, maximum_timeout=maximum_timeout)
    return beta_implementations.server(method_implementations, options=server_options)


  def beta_create_Nlp_stub(channel, host=None, metadata_transformer=None, pool=None, pool_size=None):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This function was
    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0"""
    request_serializers = {
      ('nlp.Nlp', 'Bid'): SentenceRequest2.SerializeToString,
      ('nlp.Nlp', 'CompanySegment'): SentenceRequest.SerializeToString,
      ('nlp.Nlp', 'Dependency'): SentenceRequest.SerializeToString,
      ('nlp.Nlp', 'EntityLink'): SentenceRequest.SerializeToString,
      ('nlp.Nlp', 'EventExtract'): SentenceRequest2.SerializeToString,
      ('nlp.Nlp', 'NamedIdentityRecognize'): SentenceRequest.SerializeToString,
      ('nlp.Nlp', 'OrgMatcher'): SentenceRequest.SerializeToString,
      ('nlp.Nlp', 'PosTag'): SentenceRequest.SerializeToString,
      ('nlp.Nlp', 'WordSegment'): SentenceRequest.SerializeToString,
    }
    response_deserializers = {
      ('nlp.Nlp', 'Bid'): SentenceReply.FromString,
      ('nlp.Nlp', 'CompanySegment'): SentenceReply.FromString,
      ('nlp.Nlp', 'Dependency'): SentenceReply.FromString,
      ('nlp.Nlp', 'EntityLink'): SentenceReply.FromString,
      ('nlp.Nlp', 'EventExtract'): SentenceReply.FromString,
      ('nlp.Nlp', 'NamedIdentityRecognize'): SentenceReply.FromString,
      ('nlp.Nlp', 'OrgMatcher'): SentenceReply.FromString,
      ('nlp.Nlp', 'PosTag'): SentenceReply.FromString,
      ('nlp.Nlp', 'WordSegment'): SentenceReply.FromString,
    }
    cardinalities = {
      'Bid': cardinality.Cardinality.UNARY_UNARY,
      'CompanySegment': cardinality.Cardinality.UNARY_UNARY,
      'Dependency': cardinality.Cardinality.UNARY_UNARY,
      'EntityLink': cardinality.Cardinality.UNARY_UNARY,
      'EventExtract': cardinality.Cardinality.UNARY_UNARY,
      'NamedIdentityRecognize': cardinality.Cardinality.UNARY_UNARY,
      'OrgMatcher': cardinality.Cardinality.UNARY_UNARY,
      'PosTag': cardinality.Cardinality.UNARY_UNARY,
      'WordSegment': cardinality.Cardinality.UNARY_UNARY,
    }
    stub_options = beta_implementations.stub_options(host=host, metadata_transformer=metadata_transformer, request_serializers=request_serializers, response_deserializers=response_deserializers, thread_pool=pool, thread_pool_size=pool_size)
    return beta_implementations.dynamic_stub(channel, 'nlp.Nlp', cardinalities, options=stub_options)
except ImportError:
  pass
# @@protoc_insertion_point(module_scope)
